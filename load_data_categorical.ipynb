{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fire-detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJfrfgvRgm6d"
      },
      "source": [
        "# Download and store data as pickle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHPcCECfg-TE",
        "outputId": "c8df8fa3-68a9-433a-b762-cfebf79f7cfb",
        "tags": []
      },
      "source": [
        "# !wget https://github.com/DeepQuestAI/Fire-Smoke-Dataset/releases/download/v1/FIRE-SMOKE-DATASET.zip\n",
        "# !unzip FIRE-SMOKE-DATASET.zip\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[36m1-conv-128-nodes-0-dense@2021-04-11_17:15:40.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m1-conv-128-nodes-1-dense@2021-04-11_20:04:13.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m1-conv-128-nodes-2-dense@2021-04-11_22:07:53.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m1-conv-32-nodes-0-dense@2021-04-11_15:00:06.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m1-conv-32-nodes-1-dense@2021-04-11_18:08:06.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m1-conv-32-nodes-2-dense@2021-04-11_20:49:50.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m1-conv-64-nodes-0-dense@2021-04-11_16:01:59.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m1-conv-64-nodes-1-dense@2021-04-11_18:38:49.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m1-conv-64-nodes-2-dense@2021-04-11_21:35:42.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m2-conv-128-nodes-0-dense@2021-04-11_17:25:23.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m2-conv-128-nodes-1-dense@2021-04-11_20:24:58.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m2-conv-128-nodes-2-dense@2021-04-11_22:18:13.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m2-conv-32-nodes-0-dense@2021-04-11_15:06:34.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m2-conv-32-nodes-1-dense@2021-04-11_18:15:12.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m2-conv-32-nodes-2-dense@2021-04-11_20:57:02.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m2-conv-64-nodes-0-dense@2021-04-11_16:13:22.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m2-conv-64-nodes-1-dense@2021-04-11_18:48:14.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m2-conv-64-nodes-2-dense@2021-04-11_21:44:05.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m3-conv-128-nodes-0-dense@2021-04-11_17:36:33.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m3-conv-128-nodes-1-dense@2021-04-11_20:37:28.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m3-conv-128-nodes-2-dense@2021-04-11_22:30:21.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m3-conv-32-nodes-0-dense@2021-04-11_15:17:53.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m3-conv-32-nodes-1-dense@2021-04-11_18:26:36.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m3-conv-32-nodes-2-dense@2021-04-11_21:07:57.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m3-conv-64-nodes-0-dense@2021-04-11_16:24:49.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m3-conv-64-nodes-1-dense@2021-04-11_19:16:04.model\u001b[m\u001b[m\n\u001b[1m\u001b[36m3-conv-64-nodes-2-dense@2021-04-11_21:55:54.model\u001b[m\u001b[m\n\u001b[1m\u001b[36mFIRE-SMOKE-DATASET\u001b[m\u001b[m\nFIRE-SMOKE-DATASET.zip\nREADME.md\nX.pickle\nfilter_images.py\nfire_detection_binary.ipynb\nfire_detection_categorical.ipynb\n\u001b[1m\u001b[36mfire_neutral_smoke_classifier.model\u001b[m\u001b[m\nload_data_binary.ipynb\nload_data_categorical.ipynb\n\u001b[1m\u001b[36mlogs\u001b[m\u001b[m\n\u001b[1m\u001b[36mmnist_classifier.model\u001b[m\u001b[m\ntags\ny.pickle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ROJ2Ju1gJmT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "DATA_DIR_1 = \"./FIRE-SMOKE-DATASET/Train\"\n",
        "DATA_DIR_2 = \"./FIRE-SMOKE-DATASET/Test\"\n",
        "CATEGORIES = [\"Fire\", \"Smoke\", \"Neutral\"]\n",
        "IMG_SIZE = 180"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGHeYvOggSvI",
        "outputId": "196428f2-a071-43e9-efa2-5d301ceb35b7"
      },
      "source": [
        "training_data = []\n",
        "\n",
        "import traceback\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(DATA_DIR_1, category)\n",
        "        class_num = CATEGORIES.index(category)\n",
        "        print(f'Now parsing images in {path}')\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                training_data.append([new_array, class_num])\n",
        "            except:\n",
        "                print(f'Error loading file: {os.path.join(path, img)}')\n",
        "                print(sys.exc_info())\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(DATA_DIR_2, category)\n",
        "        class_num = CATEGORIES.index(category)\n",
        "        print(f'Now parsing images in {path}')\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                training_data.append([new_array, class_num])\n",
        "            except:\n",
        "                print(f'Error loading file: {os.path.join(path, img)}')\n",
        "                print(sys.exc_info())\n",
        "    \n",
        "create_training_data()\n",
        "print(len(training_data))\n",
        "print(training_data[0][0].shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now parsing images in ./FIRE-SMOKE-DATASET/Train/Fire\n",
            "Now parsing images in ./FIRE-SMOKE-DATASET/Train/Smoke\n",
            "Now parsing images in ./FIRE-SMOKE-DATASET/Train/Neutral\n",
            "Error loading file: ./FIRE-SMOKE-DATASET/Train/Neutral/image_330.jpg\n",
            "(<class 'cv2.error'>, error(\"OpenCV(4.5.1) /private/var/folders/nz/vv4_9tw56nv9k3tkvyszvwg80000gn/T/pip-req-build-39p1qqfs/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\\n\"), <traceback object at 0x162f6df40>)\n",
            "Now parsing images in ./FIRE-SMOKE-DATASET/Test/Fire\n",
            "Now parsing images in ./FIRE-SMOKE-DATASET/Test/Smoke\n",
            "Now parsing images in ./FIRE-SMOKE-DATASET/Test/Neutral\n",
            "2999\n",
            "(180, 180, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3no0iQrgY8r"
      },
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(training_data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo4eyoEwge2l"
      },
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "    \n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "y = np.array(y)\n",
        "\n",
        "import pickle\n",
        "\n",
        "pickle_out = open(\"X_categorical.pickle\", \"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y_categorical.pickle\", \"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG-d6IHrh-GL",
        "outputId": "d5d95b60-39c3-494e-e535-c91332d67434"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\u001b[36mFIRE-SMOKE-DATASET\u001b[m\u001b[m                  fire_detection.ipynb\nFIRE-SMOKE-DATASET.zip              \u001b[1m\u001b[36mfire_neutral_smoke_classifier.model\u001b[m\u001b[m\nFIRE-SMOKE-DATASET.zip.1            \u001b[1m\u001b[36mmnist_classifier.model\u001b[m\u001b[m\nREADME.md                           tags\nX.pickle                            y.pickle\nfilter_images.py\n"
          ]
        }
      ]
    }
  ]
}